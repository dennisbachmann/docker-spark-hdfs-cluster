---
version: '3'
services:
  master:
    image: bachmann/spark-hdfs
    command: "/usr/local/bin/boot master"
    hostname: master
    container_name: spark-hdfs-cluster-master
    environment:
      SPARK_CONF_DIR: "/conf/spark"
      SPARK_PUBLIC_DNS: localhost
      MASTER: spark://master:7077
    networks:
    - hadoop
    expose:
    - 7001
    - 7002
    - 7003
    - 7004
    - 7005
    - 7006
    - 7077
    - 6066
    - 50090
    - 8020
    - 9000
    - 22
    ports:
    - 8080:8080
    - 50070:50070
    volumes:
    - "./data:/tmp/data"
    - "./application:/application"
    - "./conf/master:/conf"
  worker-1:
    image: bachmann/spark-hdfs
    command: "/usr/local/bin/boot worker"
    hostname: worker-1
    container_name: spark-hdfs-cluster-worker-1
    environment:
      SPARK_CONF_DIR: "/conf/spark"
      SPARK_PUBLIC_DNS: localhost
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 8g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
    networks:
    - hadoop
    expose:
    - 7012
    - 7013
    - 7014
    - 7015
    - 7016
    - 8881
    - 50010
    - 50020
    - 50075
    - 22
    ports:
    - 8081:8081
    volumes:
    - "./data:/tmp/data"
    - "./application:/application"
    - "./conf/worker:/conf"
  worker-2:
    image: bachmann/spark-hdfs
    command: "/usr/local/bin/boot worker"
    hostname: worker-2
    container_name: spark-hdfs-cluster-worker-2
    environment:
      SPARK_CONF_DIR: "/conf/spark"
      SPARK_PUBLIC_DNS: localhost
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 8g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8082
    networks:
    - hadoop
    expose:
    - 7012
    - 7013
    - 7014
    - 7015
    - 7016
    - 8881
    - 50010
    - 50020
    - 50075
    - 22
    ports:
    - 8082:8082
    volumes:
    - "./data:/tmp/data"
    - "./application:/application"
    - "./conf/worker:/conf"
  worker-3:
    image: bachmann/spark-hdfs
    command: "/usr/local/bin/boot worker"
    hostname: worker-3
    container_name: spark-hdfs-cluster-worker-3
    environment:
      SPARK_CONF_DIR: "/conf/spark"
      SPARK_PUBLIC_DNS: localhost
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 8g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8083
    networks:
    - hadoop
    expose:
    - 7012
    - 7013
    - 7014
    - 7015
    - 7016
    - 8881
    - 50010
    - 50020
    - 50075
    - 22
    ports:
    - 8083:8083
    volumes:
    - "./data:/tmp/data"
    - "./application:/application"
    - "./conf/worker:/conf"
  worker-4:
    image: bachmann/spark-hdfs
    command: "/usr/local/bin/boot worker"
    hostname: worker-4
    container_name: spark-hdfs-cluster-worker-4
    environment:
      SPARK_CONF_DIR: "/conf/spark"
      SPARK_PUBLIC_DNS: localhost
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 8g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8084
    networks:
    - hadoop
    expose:
    - 7012
    - 7013
    - 7014
    - 7015
    - 7016
    - 8881
    - 50010
    - 50020
    - 50075
    - 22
    ports:
    - 8084:8084
    volumes:
    - "./data:/tmp/data"
    - "./application:/application"
    - "./conf/worker:/conf"
  helper:
    image: bachmann/spark-hdfs
    command: "/usr/local/bin/boot helper"
    hostname: helper
    container_name: spark-hdfs-cluster-helper
    environment:
      SPARK_CONF_DIR: "/conf/spark"
      SPARK_PUBLIC_DNS: localhost
    networks:
    - hadoop
    volumes:
    - "./data:/tmp/data"
    - "./application:/application"
networks:
  hadoop: 
